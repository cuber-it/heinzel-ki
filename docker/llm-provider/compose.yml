# H.E.I.N.Z.E.L. — LLM Provider Gateway (Produktion)
# SQLite für Metriken, JSONL-Logs persistent in ./logs
# API-Key via .env (OPENAI_API_KEY=...)
#
# Start:  docker compose up --build -d
# Logs:   docker logs heinzel-provider-openai -f
# Ports:  12101 — Provider API (Services-Range)

networks:
  heinzel:
    external: true

services:
  provider-openai:
    build:
      context: ../..
    container_name: heinzel-provider-openai
    restart: unless-stopped
    networks:
      - heinzel
    ports:
      - "12101:8000"
    env_file: .env
    environment:
      PROVIDER_TYPE: openai
      CONFIG_PATH: /config/openai.yaml
      LOG_DIR: /logs
      LOG_REQUESTS: ${LOG_REQUESTS:-true}
      DATABASE_URL: sqlite:////data/costs.db
    volumes:
      - ../../config:/config:ro
      - ./data:/data
      - ./logs:/logs
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 10s
